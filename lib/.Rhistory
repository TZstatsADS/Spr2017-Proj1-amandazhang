ks.test(cats$Hwt, pgamma, shape = a, scale = s)
a <- cat.MM["a"]
s <- cat.MM["s"]
ks.test(cats$Hwt, pgamma, shape = a, scale = s)
ks.test(cats$Hwt, "pgamma", shape = a, scale = s)
ks.test(cats$Hwt[cats$Sex == "F"], cats$Hwt[cats$Sex == "M"])
head(iris)
data <- iris[, 3:4]
View(data)
clusters <- sample(1:3, nrow(data), replace = TRUE)
strikes <- read.csv("~/Documents/Columbia/GR5206/Lectures/strikes.csv", as.is = TRUE)
dim(strikes)
head(strikes, 3)
year.split <- split(strikes, strikes$year)
View(strikes)
max.rate <- max(year.mean[1:2, ])
year.split <- split(strikes, strikes$year)
mean_func <- function(df) {
return(apply(df[, c("unemployment", "inflation", "strike.volume")], 2, mean))
}
year.mean <- sapply(year.split, mean_func)
max.rate <- max(year.mean[1:2, ])
min.rate <- min(year.mean[1:2, ])
plot(colnames(year.mean), year.mean[1, ], xlab = "Year", ylab="Rate", type="l", ylim = c(min.rate, max.rate))
points(colnames(year.mean), year.mean[2, ], type="l", col = "red")
legend("topleft", c("Unemployment", "Inflation"), fill = c("black", "red"), cex = .5)
View(year.mean)
n <- 100
p <- 10
s <- 3
set.seed(0)
x <- matrix(rnorm(n*p), n, p)
b <- c(-0.7, 0.7, 1, rep(0, p-s))
y <- x %*% b + rt(n, df=2)
cor(x, y)
apply(x, 2, cor, y)
order(abs(cors), decreasing = TRUE)
cors <- apply(x, 2, cor, y)
order(abs(cors), decreasing = TRUE)
?grad
library(numDeriv)
?grad
plot(0,type="n",xlim=c(0,45),ylim=c(0,45),xlab="cars",ylab="trucks", cex.axis = 2, cex.lab = 2)
abline(70/3,-1/3,lty="dashed",lwd=4)
abline(80/3,-2/3, lty = "dotted",lwd=4)
legend("topright",legend=c("labor","steel"),lty=c("dotted","dashed"), lwd = c(4,4), cex = 2)
for (i in 1:30) {abline(i,-13/27,col="grey",lwd=3)}
nodes <- read.csv("~/Documents/Columbia/GR5206/HWs/ckm_nodes.csv")
View(nodes)
table(nodes$adoption_date)
sum(is.na(nodes$adoption_date))
ind_notna <- which(nodes$adoption_date!=NA)
ind_notna <- which(is.na(nodes$adoption_date))
ind_notna <- which(is.na(nodes$adoption_date)==F)
nodes <- nodes[ind_notna, ]
month.info <- table(nodes$adoption_date)[1:17]
plot(names(month.info), month.info, xlab = "Month Number", ylab = "Number of Doctors", main = "Doctors Beginning to Prescribe Each Month")
plot(names(month.info), cumsum(month.info), xlab = "Month Number", ylab = "Number of Doctors", main = "Total Doctors Prescribing Each Month")
logic_2 <- (nodes$adoption_date <=2)
index_m2 <- which(logic_2==T)
logic_14 <- (nodes$adoption_date > 14)
index_m14 <- which(logic_14==T)
network <- read.table("~/Documents/Columbia/GR5206/HWs/ckm_network.txt", sep = " ")
network <- network[index_nonna, index_nonna]
index_nonna <- which(is.na(nodes$adoption_date)==FALSE)
network <- network[index_nonna, index_nonna]
View(network)
apply(network, 2, sum)
apply(network, 2, sum)[41]
apply(network, 1, sum)[41]
nodes <- read.csv("~/Documents/Columbia/GR5206/HWs/ckm_nodes.csv")
index_nonna <- which(is.na(nodes$adoption_date)==FALSE)
nodes <- nodes[index_nonna, ]
network <- read.table("~/Documents/Columbia/GR5206/HWs/ckm_network.txt", sep = " ")
network <- network[index_nonna, index_nonna]
apply(network, 1, sum)[41]
?nlm
View(network)
View(nodes)
table(nodes$attend_meetings)
table(nodes$attend_meetings, nodes$free_time_with)
avg(c(1,2,3))
qf(0.95, 2, 27)
qf(0.05, 2, 27)
ï¼Ÿdotchart
?dotchart
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("wordcloud")
library("tidytext")
source("../lib/plotstacked.R")
setwd("~/scr/ADS-Spring2017/Spr2017-Proj1-amandazhang/lib")
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("wordcloud")
library("tidytext")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
f.speechlinks=function(html.page, node.type=".ver12 a"){
urls <- html.page %>% # feed `main.page` to the next step
html_nodes(node.type) %>% # get the CSS nodes
html_attr("href") # extract the URLs
# Get link text
links <- main.page %>% # feed `main.page` to the next step
html_nodes(node.type) %>% # get the CSS nodes
html_text() # extract the link text
# Combine `links` and `urls` into a data.frame
out <- data.frame(links = links, urls = urls, stringsAsFactors = FALSE)
return(out)
}
#Inauguaral speeches
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
# Get link URLs
# f.speechlinks is a function for extracting links from the list of speeches.
inaug=f.speechlinks(main.page)
#head(inaug)
as.Date(inaug[,1], format="%B %e, %Y")
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.
# The inauglist contains information of 45 presidents' inauguration address length,
# term and date
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
inaug.list=cbind(inaug.list, inaug)
inaug.list$fulltext=NA
for(i in seq(nrow(inaug.list))) {
text <- read_html(inaug.list$urls[i]) %>% # load the page
html_nodes(".displaytext") %>% # isloate the text
html_text() # get the text
inaug.list$fulltext[i]=text
# Create the file name
filename <- paste0("../data/fulltext/",
inaug.list$type[i],
inaug.list$File[i], "-",
inaug.list$Term[i], ".txt")
sink(file = filename) %>% # open file to write
cat(text)  # write the file
sink() # close the file
}
inauguration <- character()
for (i in 1:nrow(inaug.list)) {
inauguration[i] <- inaug.list$fulltext[i]
}
stop_words <- stopwords("SMART")
# pre-processing:
inauguration <- gsub("'", "", inauguration)  # remove apostrophes
inauguration <- gsub("[[:punct:]]", " ", inauguration)  # replace punctuation with space
inauguration <- gsub("[[:cntrl:]]", " ", inauguration)  # replace control characters with space
inauguration <- gsub("^[[:space:]]+", "", inauguration) # remove whitespace at beginning of documents
inauguration <- gsub("[[:space:]]+$", "", inauguration) # remove whitespace at end of documents
inauguration <- tolower(inauguration)  # force to lowercase
# tokenize on space and output as a list:
doc.list <- strsplit(inauguration, "[[:space:]]+")
# compute the table of terms:
term.table <- table(unlist(doc.list))
term.table <- sort(term.table, decreasing = TRUE)
# remove terms that are stop words or occur fewer than 5 times:
del <- names(term.table) %in% stop_words | term.table < 5
term.table <- term.table[!del]
vocab <- names(term.table)
# now put the documents into the format required by the lda package:
get.terms <- function(x) {
index <- match(x, vocab)
index <- index[!is.na(index)]
rbind(as.integer(index - 1), as.integer(rep(1, length(index))))
}
documents <- lapply(doc.list, get.terms)
# Using the R package 'lda' for model fitting
# Compute some statistics related to the data set:
D <- length(documents)  # number of documents
W <- length(vocab)  # number of terms in the vocab
doc.length <- sapply(documents, function(x) sum(x[2, ]))  # number of tokens per document
N <- sum(doc.length)  # total number of tokens in the data
term.frequency <- as.integer(term.table)  # frequencies of terms in the corpus
# MCMC and model tuning parameters:
K <- 15
G <- 5000
alpha <- 0.02
eta <- 0.02
# Fit the model:
library(lda)
set.seed(357)
fit <- lda.collapsed.gibbs.sampler(documents = documents, K = K, vocab = vocab,
num.iterations = G, alpha = alpha,
eta = eta, initial = NULL, burnin = 0,
compute.log.likelihood = TRUE)
theta <- t(apply(fit$document_sums + alpha, 2, function(x) x/sum(x)))
phi <- t(apply(t(fit$topics) + eta, 2, function(x) x/sum(x)))
InaugReviews <- list(phi = phi,
theta = theta,
doc.length = doc.length,
vocab = vocab,
term.frequency = term.frequency)
library(LDAvis)
json <- createJSON(phi = InaugReviews$phi,
theta = InaugReviews$theta,
doc.length = InaugReviews$doc.length,
vocab = InaugReviews$vocab,
term.frequency = InaugReviews$term.frequency)
serVis(json, out.dir = 'vis', open.browser = FALSE)
library(shiny)
ui <- shinyUI(
fluidPage(
sliderInput("nTerms", "Number of terms to display", min = 20, max = 40, value = 30),
visOutput('myChart')
)
)
server <- shinyServer(function(input, output, session) {
output$myChart <- renderVis({
if(!is.null(input$nTerms)){
with(InaugReviews,
createJSON(phi, theta, doc.length, vocab, term.frequency,
R = input$nTerms))
}
})
})
shinyApp(ui = ui, server = server)
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
inaug=f.speechlinks(main.page)
as.Date(inaug[,1], format="%B %e, %Y")
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
inaug.list=cbind(inaug.list, inaug)
inaug.list$fulltext=NA
for(i in seq(nrow(inaug.list))) {
text <- read_html(inaug.list$urls[i]) %>% # load the page
html_nodes(".displaytext") %>% # isloate the text
html_text() # get the text
inaug.list$fulltext[i]=text
# Create the file name
filename <- paste0("../data/fulltext/",
inaug.list$type[i],
inaug.list$File[i], "-",
inaug.list$Term[i], ".txt")
sink(file = filename) %>% # open file to write
cat(text)  # write the file
sink() # close the file
}
for(i in seq(nrow(inaug.list))) {
text <- read_html(inaug.list$urls[i]) %>% # load the page
html_nodes(".displaytext") %>% # isloate the text
html_text() # get the text
inaug.list$fulltext[i]=text
# Create the file name
filename <- paste0("../data/fulltext/",
inaug.list$type[i],
inaug.list$File[i], "-",
inaug.list$Term[i], ".txt")
sink(file = filename) %>% # open file to write
cat(text)  # write the file
sink() # close the file
}
sentence.list=NULL
for(i in 1:nrow(inaug.list)){
sentences=sent_detect(inaug.list$fulltext[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
# colnames(emotions)=paste0("emo.", colnames(emotions))
# in case the word counts are zeros?
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
sentence.list=rbind(sentence.list,
cbind(inaug.list[i,-ncol(inaug.list)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
sentence.list=
sentence.list%>%
filter(!is.na(word.count))
sel.comparison=c("DonaldJTrump","JohnMcCain", "GeorgeBush", "MittRomney", "GeorgeWBush",
"RonaldReagan","AlbertGore,Jr", "HillaryClinton","JohnFKerry",
"WilliamJClinton","HarrySTruman", "BarackObama", "LyndonBJohnson",
"GeraldRFord", "JimmyCarter", "DwightDEisenhower", "FranklinDRoosevelt",
"HerbertHoover","JohnFKennedy","RichardNixon","WoodrowWilson",
"AbrahamLincoln", "TheodoreRoosevelt", "JamesGarfield",
"JohnQuincyAdams", "UlyssesSGrant", "ThomasJefferson",
"GeorgeWashington", "WilliamHowardTaft", "AndrewJackson",
"WilliamHenryHarrison", "JohnAdams")
View(sentence.list)
sentence.list.sel=sentence.list%>%filter(File%in%sel.comparison, Term==1)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
par(mar=c(4, 11, 2, 2))
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=2, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
par(mar=c(1,1))
par(mar=c(1,1,1,1))
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=2, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
?beeswarm
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=2, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.5,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.2,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.3, cex.lab=0.2,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.5, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.7, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.2, cex.axis=0.7, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.6, cex.axis=0.7, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=1, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
View(sentence.list.sel)
View(sentence.list)
View(sentence.list.sel)
unique(sentence.list.sel$President)
mean(sentence.list.sel$word.count[sentence.list.sel$President=="Barack Obama"])
mean(sentence.list.sel$word.count[sentence.list.sel$President=="Donald Y. Trump"])
mean(sentence.list.sel$word.count[sentence.list.sel$President=="Donald J. Trump"])
View(inaug)
View(inaug.list)
library(plotly)
install.packages("plotly")
x <- unique(inaug.list$President)
y1 <- inaug.list$Words[inaug.list$Term==1]
x
length(sel.comparison)
x[-20]
length(unique(inaug.list$President))
inaug.list$President=="John Adams"&inaug.list$Term==2
inaug.list$President=="George Washington"&inaug.list$Term==2
any(inaug.list$President=="John Adams"&inaug.list$Term==2)
any(inaug.list$President=="George Washington"&inaug.list$Term==2)
which(inaug.list$President=="George Washington"&inaug.list$Term==2)
which(inaug.list$President=="John Adams"&inaug.list$Term==2)
y2 <- NULL
for (i in inaug.list$President) {
ifelse(any(inaug.list$President==i & inaug.list$Term==2) == T, y2[i] <- inaug.list$Words[which(inaug.list$President==i & inaug.list$Term==2)], 0)
}
y2
names(y2)
y2 <- NULL
for (i in inaug.list$President) {
y2[i] <- ifelse(any(inaug.list$President==i & inaug.list$Term==2) == T, inaug.list$Words[which(inaug.list$President==i & inaug.list$Term==2)], 0)
}
y2
x <- unique(inaug.list$President)
x <- x[-18]
x
y1 <- inaug.list$Words[inaug.list$Term==1]
y1
y2
x <- unique(inaug.list$President)
x
x <- unique(inaug.list$President)
x <- x[-20]
x
y1 <- inaug.list$Words[inaug.list$Term==1]
names(y1) <- x
y1
y2
y2[18] <- y2[20]
y2
y2 <- y2[-20]
y2
data <- data.frame(x, y1, y2)
View(data)
data$x <- factor(data$x, levels = data[["x"]])
p <- plot_ly(data, x = ~x, y = ~y1, type = 'bar', name = 'Primary Product', marker = list(color = 'rgb(49,130,189)')) %>%
add_trace(y = ~y2, name = 'Secondary Product', marker = list(color = 'rgb(204,204,204)')) %>%
layout(xaxis = list(title = "", tickangle = -45),
yaxis = list(title = ""),
margin = list(b = 100),
barmode = 'group')
library(plotly)
p <- plot_ly(data, x = ~x, y = ~y1, type = 'bar', name = 'Primary Product', marker = list(color = 'rgb(49,130,189)')) %>%
add_trace(y = ~y2, name = 'Secondary Product', marker = list(color = 'rgb(204,204,204)')) %>%
layout(xaxis = list(title = "", tickangle = -45),
yaxis = list(title = ""),
margin = list(b = 100),
barmode = 'group')
chart_link = plotly_POST(p, filename="bar/rotated")
chart_link
p
p
p <- plot_ly(data, x = ~x, y = ~y1, type = 'bar', name = 'First Term', marker = list(color = 'rgb(49,130,189)')) %>%
add_trace(y = ~y2, name = 'Second Term', marker = list(color = 'rgb(204,204,204)')) %>%
layout(xaxis = list(title = "", tickangle = -45),
yaxis = list(title = ""),
margin = list(b = 100),
barmode = 'group')
p
ui <- shinyUI(
fluidPage(
sliderInput("nTerms", "Number of terms to display", min = 20, max = 40, value = 30),
visOutput('myChart')
)
)
server <- shinyServer(function(input, output, session) {
output$myChart <- renderVis({
if(!is.null(input$nTerms)){
with(InaugReviews,
createJSON(phi, theta, doc.length, vocab, term.frequency,
R = input$nTerms))
}
})
})
shinyApp(ui = ui, server = server)
print(R.version)
